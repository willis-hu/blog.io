---
layout: post
title: 一种新型的深度结构-和积网络简介
date: 2017-11-24
categories: blog
tags: [深度学习]
description: spn简介
---

星期六, 25. 十一月 2017 10:29上午 

SPN是一种近几年新提出的深度结构，它可以在高树宽模型上进行简单、直接的推导，以下是对SPN作的一些基础介绍：

#### 多线性函数

一个多线性函数 $Φ(x)$ 是一种未归一化的概率分布，更具体地，它是一种在指示变量上的多重线性函数。

SPN可以应用于多值离散随机变量或者连续随机变量，但在为了简化表达，本文中我们只讨论二值的随机变量，即只有0和1。

假设我们有随机变量$X_1, \dots X_n \in \{0, 1\}$,变量的取值组合都含有一定的概率，对某些取值求边缘概率意味着求其他无关变量的值为任意值的概率之和。我们可以利用一个多重线性函数来表述这个边缘分布。我们可以定义以下的多重线性函数：

$$ f : \{0, 1\}^n \times \{0, 1\}^n \rightarrow R^+ $$

同时我们定义网络多项式为：

$$ \begin{aligned} \Phi(x_1, \dots, x_n, \overline{x}_1, \dots, \overline{x}_n) =  &P(X_1 = 0, X_2 = 0, \dots, X_n = 0) \overline{x}_1\overline{x}_2\dots\overline{x}_n + \\ &P(X_1 = 1, X_2 = 0, \dots, X_n = 0) x_1 \overline{x}_2\dots\overline{x}_n + \\ &P(X_1 = 0, X_2 = 1, \dots, X_n = 0) \overline{x}_1 x_2\dots\overline{x}_n + \\ &P(X_1 = 1, X_2 = 1, \dots, X_n = 0) x_1 x_2\dots\overline{x}_n + \\ &\dots + \\ &P(X_1 = 1, X_2 = 1, \dots, X_n = 1) x_1 x_2 \dots x_n \\ \end{aligned} $$

这个网络多项式将所有可能的分布与它对应的概率值相乘，之后求总和。其中，\\(X_k\\)是随机变量，而\\(x_k\\)和\\(\overline{x}_k\\)是指示变量，它们的值表示了f是否应当包含\\(X_k\\)发生的概率，若事件发生，则\\(x_k=1\\)，否则\\(\overline{x}_k=1\\)。

- 需要注意的是，我们经常同时设置x和\\(\overline{x}\\),即使\\(X_{k}\\)并不能同时为0和1，当我们在设置\\(x_k\\)和\\(\overline{x_k}\\)同时为1时，类似于我们在求\\(X_{k}\\)的边缘概率值。

和积网络对概率分布的清晰的表达方式允许我们实现很多种操作：

1. 查询某个具体事件的概率。

2. 计算配分函数。

3. 对变量集合进行边缘化，当我们需要计算\\(x_{k+1} 到 x_n\\)的边缘概率时，只需要将\\(x_1 到 x_k\\)都置为1，同时它们的非也置为1，其余变量依照事件中真实取值填写，则求出的值为边缘概率。

#### 计算能力：

- 多线性的表达方式使得我们易于对模型进行学习和推导，例如边缘化或者计算配分函数。然而，网络多项式中包含\\(2^n\\)个元素所以它的计算依然是复杂的。SPN保证了只含有一个多线性函数并且以简式方式计算。特别地，spn必须包含多个交替的sum层和product层，这保证了Φ可以在线性事件内计算得到。

#### 结构：

- 通常，SPN是一个有向无环图。图的叶节点和变量相关，例如网络多项式中的\\(x_i\\)。图的内部节点包括sum节点和product节点，sum节点的父节点始终为produt节点，反之亦如此。从product节点到sum节点之间的边为权重。

![spn-pic](http://willis-hu.github.io/img/spn-pic.png)

例如上图所示，它所代表的公式为

$$ \begin{aligned} S(x_1, x_2, x_3, \overline{x}_1, \overline{x}_2, \overline{x}_3) = &0.8x_1(0.3x_2 + 0.7\overline{x}_2)(0.6x_3 + 0.4\overline{x}_3) + \\ &0.2\overline{x}_1(0.5x_2 + 0.5\overline{x}_2)(0.9x_3 + 0.1\overline{x}_3) \\ \end{aligned} $$

为了能通过给定的X计算对应的SPN值，我们需要安排叶节点使得他们能符合给定的X值并且能将sum和product传递到根节点。一般情况下，我们有\\(S(x) = \Phi(x)\\)。接下来，计算某个事件的概率，计算配分函数和部分变量集合的边缘化都可以实现：

1. 计算某个事件的概率，例如\\(X_1 = 1, X_2 = 0, X_3 = 1\\)的概率表示为

$$ \begin{aligned}S(1, 0, 1, 0, 1, 0) = &0.8(0 + 0.7)(0.6 + 0) + 0(0 + 0.5)(0.9 + 0)\\ = &0.336\\ \end{aligned} $$

2. 计算配分函数：

$$ \begin{aligned}S(1, 1, 1, 1, 1, 1) = &0.8(0.3 + 0.7)(0.6 + 0.4) + 0.2(0.5 + 0.5)(0.9 + 0.1) \\= &0.8 + 0.2 \\ = &1 \\ \end{aligned} $$ 

3. 计算边缘概率，例如\\(X_1 = 1, X_2=0\\)的概率：

$$ \begin{aligned}S(1, 0, 1, 0, 1, 1) = &0.8(0 + 0.7)(0.6 + 0.4) + 0(0.5 + 0.5)(0.9 + 0.1) \\ = &0.8 * 0.7 * 1 + 0 \\ = &0.56 \end{aligned} $$

#### 训练

SPN可以通过生成方法或者判别方法训练。SPN通过一个密集连接结构和随机的权重进行初始化。之后，在生成模型中，我们计算给定数据的对数似然值关于权重的导数，在判别模型中，我们计算给定输入下的输出变量的条件对数似然值关于权重的导数。得到这些偏导数之后，我们根据导数的值，利用梯度下降法或其他方法更新权重的值。
