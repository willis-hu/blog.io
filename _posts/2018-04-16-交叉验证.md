---
layout: post
title: 机器学习中的交叉验证
date: 2018-04-16
categories: 机器学习
tags: [机器学习]
description: 对于交叉验证的理解
---

#### 为什么需要交叉验证

机器学习中，把全部数据全都用来学习，就会很容易导致过拟合问题。采样交叉验证可以验证模型是否过拟合，从而根据交叉验证的结果选择更优的模型。

#### 交叉验证的作用

交叉验证的思想中，一般将数据分为训练集和验证集，在训练集上进行模型训练，验证集上验证模型的预测结果，若模型过拟合，则验证集上的准确率或者AUC等会较小。而相对而言，验证集上的评估指标越好，则模型相对越好。举个栗子，对于kNN模型，模型训练时设置不同的k会得到不同的模型，此时我们需要评估哪个模型更优，若使用留出法，可能由于选取的训练数据的不同得到不同的分类规则，验证集上的评估效果并不一定能够反映使用全部数据进行训练后得到的模型的预测结果。但是对于k折交叉验证，由于任何数据都有过多个包含该数据的模型，则单次划分引进的误差会被削弱，因而可以更好的评估模型的效果。

#### 交叉验证的方法

交叉验证一般分为以下两种方法：
  - 留出法：将训练数据划分为两部分，包括训练集和验证集，一般训练集要大于总体数据的50%，通过对比训练集和验证集上评估指标的差异可以推测该模型是否过拟合。留出法的优点是计算较为简单。缺点是验证集会带走一部分数据，导致训练时不能学习到所有的数据，该方法对于数据的划分比例，以及划分方式较为敏感，若划分出的验证集和原始数据集在分布上有较大差异，则训练结果可能会出现欠拟合。
  - k折交叉验证：将训练数据随机划分为K部分，k一般取10，之后选取K-1部分作为训练集，余下的1部分作为验证集，在这k个数据划分上训练出k个模型，这k个模型都有各自对应的测试集，通过在测试集上进行预测，得到k个模型的评估指标，对这k个指标求平均，则得到该训练参数下模型的评估指标值。通过对不同参数下模型评估指标值进行对比，得到最佳的模型。该方法的好处在于通过对k个不同分组训练的评估结果做平均来减少方差，因此模型的性能对数据的划分就不是那么敏感。使用k折交叉验证得到的模型评估也更加准确。
  - 留一法；对k折交叉验证中的k设置为N，即每一个样本都会又一次作为验证集的机会，该方法下模型的训练数据基本可以等同于整体数据，该方法得到的评估指标基本上可以认为是模型训练了全部数据后的评估指标，但这种方法的计算量太大，对于N个样本就会有N个模型，训练的成本太大。

#### k折交叉验证的过程

  - 第一步，不重复抽样将原始数据随机分为 k 份。
  - 第二步，每一次挑选其中 1 份作为测试集，剩余 k-1 份作为训练集用于模型训练。
  - 第三步，重复第二步 k 次，这样每个子集都有一次机会作为测试集，其余机会作为训练集。
  - 在每个训练集上训练后得到一个模型，
  - 用这个模型在相应的测试集上测试，计算并保存模型的评估指标，
  - 第四步，计算 k 组测试结果的平均值作为模型精度的估计，并作为当前 - k 折交叉验证下模型的性能指标。
