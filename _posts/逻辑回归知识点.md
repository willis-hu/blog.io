sklearn中的logisticRegression方法：
    1. decision_function(X)，返回实例距离分离超平面的带符号距离。
    2. densify()，将模型参数输出为ndarray格式。
    3. fit(X,y,sample_weight)，通过训练数据训练模型。
    4. get_params()，返回模型参数。
    5. predict(X),返回x样本属于的类
    6. predict_proba(X),返回样本属于某一类的概率，概率和为1.0
    7. predict_log_proba(X),返回概率的对数形式
    8. score(X, y, sample_weight=None) 返回在测试集上的平均准确率
    9. set_params(params)，设置模型参数
    10. saprsify()，将模型参数输出为scipy.sparse格式。


sklearn里的[逻辑回归函数](http://www.cnblogs.com/pinard/p/6035872.html)：
  1. LogisticRegression
  2. LogisticRegressionCV
  3. logistic_regression_path
前两者的差别在于LogisticRegressionCV使用了交叉验证来选择正则化系数C，而LogisticRegression需要每次自己制定一个正则化系数。

LogisticRegression的参数部分：
    1. penalty，可选择l1或者l2,默认的是l2正则，注意这里l1可以处理特征过多的情况。
    2. solver。即选择优化的方法。可选的有；
        1. liblinear，坐标轴下降法。只支持ovr。
        2. lbfgs，newton-cg，牛顿法。
        3. sag，随机平均梯度下降。
    3. multi_class。可以选择使用ovr或者multinomial，对于二分类二者无差别，对于多分类ovr是使用一对多的分类方法，multinomial使用多对多的方法。ovr相对简单，但是分类效果相对略差，multinomial分类相对精确，但是分类速度没有ovr快。此外，multinomial不可以采用liblinear优化方法。
    4. class_weight，类型权重参数。用于标示分类模型中各种类型的权重，用于解决误分类问题或者样本失衡问题。目的是对样本的重要性加以区别，对于class_weight高的样本如果分类错误，则损失函数会带来更多的loss，即class_weight高的类别有更高的权重。
    5. sample_weight,样本权重参数。针对样本修改权重，比如某些样本来自重要区域，则增加它的权重用以增加分类错误的损失，这时候最后的损失应该是训练损失*class_weight*sample_weight。
    6. 正则化参数c
    7. 迭代次数
    8. 停止条件
